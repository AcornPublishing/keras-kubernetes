{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow CPU vs GPU times",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/dattarajrao/keras2kubernetes/blob/master/TensorFlow_CPU_vs_GPU_times.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "YNvYXHDQLaYz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ***Import TensorFlow library and check if Cloud runtime has a GPU***"
      ]
    },
    {
      "metadata": {
        "id": "7PUq3_MNNStH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abefe468-f894-4128-dab2-3b06f4c36cbf"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found')\n",
        "else:\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tJMs1cWLNFM1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ***Load the CIFAR-10 Dataset in memory***"
      ]
    },
    {
      "metadata": {
        "id": "WZCB7rH8Zx-d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cifar = tf.keras.datasets.cifar10\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = cifar.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rJufkCFhNW7y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ***Build the Convolutional Neural Network Model***"
      ]
    },
    {
      "metadata": {
        "id": "7XcZ8ZNrHOgI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "d5823aee-520e-4f50-d177-1cf67e94ec37"
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    \n",
        "  tf.keras.layers.Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]),\n",
        "  tf.keras.layers.Activation('relu'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), padding='same'),\n",
        "  tf.keras.layers.Activation('relu'),\n",
        "  tf.keras.layers.Conv2D(64, (3, 3)),\n",
        "  tf.keras.layers.Activation('relu'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.Dropout(0.25),\n",
        "    \n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,667,594\n",
            "Trainable params: 1,667,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wx_4YHd2NozD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ***Train the Model and record Training Time***"
      ]
    },
    {
      "metadata": {
        "id": "ZO8T0BiQNuqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2b77fc8e-4b8d-4844-9822-bc8cad0dabeb"
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "# start training\n",
        "st_time = datetime.datetime.now()\n",
        "\n",
        "model.fit(x_train, y_train, epochs=1)\n",
        "\n",
        "# record time after training\n",
        "end_time = datetime.datetime.now()\n",
        "\n",
        "print('Training time = %s'%(end_time-st_time))\n",
        "\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "50000/50000 [==============================] - 24s 478us/step - loss: 1.4407 - acc: 0.4763\n",
            "Training time = 0:00:24.654200\n",
            "10000/10000 [==============================] - 1s 141us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.151843452835083, 0.582]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "cRJM7ofpN1Yk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ***Save the Model file***"
      ]
    },
    {
      "metadata": {
        "id": "FjCjXh9rgucy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('my_cifar_cnn.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vT0S0SnFN6NZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ***Load Model and do Inference - Record times***"
      ]
    },
    {
      "metadata": {
        "id": "udVuo3qziO5u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b663e134-4b7d-4848-cff0-141fa9b914de"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "newmodel = load_model('my_cifar_cnn.h5')\n",
        "\n",
        "# start inference - for 1000 tests\n",
        "st_time = datetime.datetime.now()\n",
        "\n",
        "for count in range(1000):\n",
        "  prediction = newmodel.predict(np.expand_dims(x_test[count], axis=0))\n",
        "  #print(y_test[count][0])\n",
        "  #print(np.argmax(prediction))\n",
        "  #print('----')\n",
        "  \n",
        "# record time after inference\n",
        "end_time = datetime.datetime.now()\n",
        "\n",
        "print('Inference time = %s'%(end_time-st_time))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inference time = 0:00:02.178994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vzxj6-6cLXeC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}